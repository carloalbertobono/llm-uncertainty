{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ab59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e332ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"turl_test_2k_prompts_50.jsonl\"\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model_name = \"osunlp/TableLlama\"\n",
    "config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=orig_ctx_len, padding_side=\"left\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d387cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt formatting\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_seg}\\n\\n### Question:\\n{question}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def generate_prompt(instruction, question, input_seg=None):\n",
    "    question += \" Answer with just a candidate, selected from the provided referent entity candidates list, and nothing else. The selected candidate must be reported verbatim from the list provided as input. Each candidate in the list is enclosed between < and > and reports [DESC] and [TYPE] information.\"\n",
    "    if input_seg:\n",
    "        return PROMPT_DICT[\"prompt_input\"].format(instruction=instruction, input_seg=input_seg, question=question)\n",
    "    else:\n",
    "        return PROMPT_DICT[\"prompt_no_input\"].format(instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947af3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 37203968\r\n",
      "drwx------  1 bono  staff   1.0M Feb 17 08:52 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rwx------@ 1 bono  staff   4.4G Mar  7 12:23 \u001b[31mTableLlama.1548780410.pickle\u001b[m\u001b[m\r\n",
      "drwx------  1 bono  staff   1.0M Mar  7 14:45 \u001b[34m.\u001b[m\u001b[m\r\n",
      "-rwx------  1 bono  staff   4.0K Mar  7 14:46 \u001b[31m._TableLlama.1548780410.pickle\u001b[m\u001b[m\r\n",
      "-rwx------@ 1 bono  staff   4.4G Mar  8 14:55 \u001b[31mTableLlama.2573653229.pickle\u001b[m\u001b[m\r\n",
      "-rwx------  1 bono  staff   4.0K Mar  8 14:56 \u001b[31m._TableLlama.2573653229.pickle\u001b[m\u001b[m\r\n",
      "-rwx------@ 1 bono  staff   4.4G Mar  9 10:21 \u001b[31mTableLlama.1765523202.pickle\u001b[m\u001b[m\r\n",
      "-rwx------  1 bono  staff   4.0K Mar  9 10:27 \u001b[31m._TableLlama.1765523202.pickle\u001b[m\u001b[m\r\n",
      "-rwx------@ 1 bono  staff   4.4G Mar 10 08:18 \u001b[31mTableLlama.940523022.pickle\u001b[m\u001b[m\r\n",
      "-rwx------  1 bono  staff   4.0K Mar 10 08:35 \u001b[31m._TableLlama.940523022.pickle\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -larth \"/Volumes/ssd/uncertainty/tablellama su 1800 prompts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d97183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableLlama.1548780410.pickle\n",
      "TableLlama.1765523202.pickle\n",
      "TableLlama.2573653229.pickle\n",
      "TableLlama.940523022.pickle\n",
      "CPU times: user 1min 58s, sys: 49.7 s, total: 2min 48s\n",
      "Wall time: 2min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load processed data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "prefix = '/Volumes/ssd/uncertainty/tablellama su 1800 prompts/'\n",
    "\n",
    "run = 0\n",
    "\n",
    "outlist = []\n",
    "for file in os.listdir(prefix):\n",
    "    if file.endswith('pickle') and not file.startswith('.'):\n",
    "        print(file)\n",
    "        with open(os.path.join(prefix, file), 'rb') as handle:\n",
    "            outlist_ = pickle.load(handle)\n",
    "           \n",
    "            for pid, o in enumerate(outlist_):\n",
    "                del o['pre_output_proba_topn']\n",
    "                del o['pre_output_proba_topk']\n",
    "                del o['pre_output_true_entropies']\n",
    "                del o['post_output_proba_topn']\n",
    "                del o['post_output_proba_topk']\n",
    "                del o['post_output_true_entropies']\n",
    "                o['run'] = run\n",
    "                o['pid'] = pid\n",
    "                outlist.append(o)\n",
    "        run += 1\n",
    "\n",
    "len(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6ce8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if False:\n",
    "    with open('1800.pickle', 'wb') as handle:\n",
    "        pickle.dump(outlist, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('1800.pickle', 'rb') as handle:\n",
    "        outlist = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab98ed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007b83e",
   "metadata": {},
   "source": [
    "### check outputs against ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b59b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4857 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 2.28 s, total: 1min 11s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# show results\n",
    "\n",
    "c=0\n",
    "t=0\n",
    "h=0\n",
    "\n",
    "truth = []\n",
    "\n",
    "for idx, p in enumerate(outlist):\n",
    "    print(idx, end='\\r')\n",
    "    c+=1\n",
    "    # in\n",
    "    prompt = generate_prompt(p[\"instruction\"], p[\"question\"], p[\"input\"])\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    # computed\n",
    "    # post_output_scores = p['post_output_scores']\n",
    "    post_output_sequences = p['post_output_sequences']\n",
    "    # bases\n",
    "    baseid = len(inputs[\"input_ids\"][0]) + 1\n",
    "    endid = len(post_output_sequences[0])\n",
    "    # lookout\n",
    "    generated_ids = post_output_sequences\n",
    "    generated_text = tokenizer.decode(generated_ids[0][baseid:endid], skip_special_tokens=True)\n",
    "    # print\n",
    "    # print(generated_text)\n",
    "    # print(p['output'])\n",
    "    # print('\\n')\n",
    "    #test\n",
    "    a = generated_text.lower().strip()\n",
    "    b = p['output'].lower().strip()\n",
    "    # correct\n",
    "    correct = False\n",
    "    if (a in b) or (b in a) or (b.startswith(a)) or (a.startswith(b)): \n",
    "        correct = True\n",
    "        t+=1\n",
    "    # hallucinated\n",
    "    elif a not in prompt.lower().strip(): \n",
    "        h+=1\n",
    "    # incorrect\n",
    "    else:\n",
    "        pass\n",
    "        #print(generated_text)\n",
    "        #print(p['output'])\n",
    "        #print('\\n')\n",
    "        # print(prompt)\n",
    "        # print('\\n')\n",
    "        \n",
    "    truth.append((p['run'], p['pid'], correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc34a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.DataFrame(truth, columns=['run', 'pid', 'correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9840ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1801\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.groupby('pid').size().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583aa919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='correct', ylabel='Count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(truth.groupby('pid').correct.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c9aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = truth.groupby('pid').correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efd3d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu[accu<1.].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c5662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "0.00    125\n",
       "0.75    107\n",
       "0.50     78\n",
       "0.25     34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu[accu<1.].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all prompts with errors plus a sample of noerrors\n",
    "err_idx = accu[accu<1.].index.tolist()\n",
    "noerr_idx = accu[accu==1.].sample(len(accu[accu<1.]), random_state=42).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f19ee6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(err_idx) & set(noerr_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80143637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_pids = set(err_idx) | set(noerr_idx)\n",
    "len(selected_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f3417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableLlama.1548780410.pickle\n",
      "TableLlama.1765523202.pickle\n",
      "TableLlama.2573653229.pickle\n",
      "TableLlama.940523022.pickle\n",
      "CPU times: user 2min 20s, sys: 2min 3s, total: 4min 23s\n",
      "Wall time: 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load processed data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "prefix = '/Volumes/ssd/uncertainty/tablellama su 1800 prompts/'\n",
    "\n",
    "run = 0\n",
    "\n",
    "outlist = []\n",
    "for file in os.listdir(prefix):\n",
    "    if file.endswith('pickle') and not file.startswith('.'):\n",
    "        print(file)\n",
    "        with open(os.path.join(prefix, file), 'rb') as handle:\n",
    "            outlist_ = pickle.load(handle)\n",
    "           \n",
    "            for pid, o in enumerate(outlist_):\n",
    "                if pid in selected_pids:\n",
    "                    o['run'] = run\n",
    "                    o['pid'] = pid\n",
    "                    outlist.append(o)\n",
    "        run += 1\n",
    "\n",
    "len(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b4b62d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['table', 'cell', 'instruction', 'input', 'question', 'output', 'pre_output_proba_topn', 'pre_output_proba_topk', 'pre_output_true_entropies', 'post_output_sequences', 'post_output_proba_topn', 'post_output_proba_topk', 'post_output_true_entropies', 'elapsed', 'run', 'pid'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlist[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57d940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1beafeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlist[-1]['run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc9317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('644.data.pickle', 'wb') as handle:\n",
    "    pickle.dump(outlist, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "749ad873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 43159720\r\n",
      "-rw-r--r--@  1 bono  staff    15M May 14  2024 turl_test_2k_prompts_50.jsonl\r\n",
      "-rw-r--r--   1 bono  staff    17B Feb 10 10:37 README.md\r\n",
      "-rwx------@  1 bono  staff   4.8K Feb 19 14:05 \u001b[31mrunner.py\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   137M Feb 19 16:32 gemma-2-2b-it.3892595837.pickle\r\n",
      "-rw-r--r--@  1 bono  staff   5.0K Feb 20 09:23 prompt100.py\r\n",
      "-rw-r--r--   1 bono  staff    16M Feb 20 20:07 tablellama.preprocessed.pickle\r\n",
      "-rw-r--r--@  1 bono  staff   5.2K Feb 20 21:04 prompt100tablellama.py\r\n",
      "-rw-r--r--   1 bono  staff   117M Feb 22 09:11 gemma-2-9b-it-4bit.3246737286.pickle\r\n",
      "drwxr-xr-x   4 bono  staff   128B Feb 27 07:56 \u001b[34mmirror\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 11 bono  staff   352B Feb 27 08:19 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 bono  staff   5.3K Mar  2 14:55 prompt100gemmalocal.py\r\n",
      "-rw-r--r--   1 bono  staff   222K Mar  4 13:37 jensension.ipynb\r\n",
      "drwxr-xr-x   4 bono  staff   128B Mar  5 20:03 \u001b[34molder tablellama\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  12 bono  staff   384B Mar  6 15:38 \u001b[34mtablellama10runs\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   450K Mar  6 16:03 tablellama-multipass.ipynb\r\n",
      "-rw-r--r--   1 bono  staff   450K Mar  6 16:09 tablellama-plot copy.ipynb\r\n",
      "drwxr-xr-x  16 bono  staff   512B Mar  6 17:50 \u001b[34m.git\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 bono  staff   6.2K Mar  6 19:31 prompt_wip.py\r\n",
      "-rw-rw----@  1 bono  staff   1.3M Mar  7 14:52 delme.xlsx\r\n",
      "-rw-r--r--   1 bono  staff   726K Mar  7 15:06 logits-tablellama.ipynb\r\n",
      "-rw-r--r--   1 bono  staff   779K Mar  7 15:41 tablellama-plot.ipynb\r\n",
      "-rw-r--r--@  1 bono  staff   4.4G Mar  8 13:37 TableLlama.2573653229.pickle\r\n",
      "drwxr-xr-x   2 bono  staff    64B Mar  8 14:54 \u001b[34mtest\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 bono  staff   8.0K Mar  8 14:54 .DS_Store\r\n",
      "-rw-r--r--@  1 bono  staff   4.4G Mar  9 10:21 TableLlama.1765523202.pickle\r\n",
      "-rw-r--r--@  1 bono  staff   4.4G Mar 10 08:18 TableLlama.940523022.pickle\r\n",
      "drwxr-xr-x   9 bono  staff   288B Mar 10 08:36 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   127M Mar 10 08:46 1800.pickle\r\n",
      "-rw-r--r--   1 bono  staff    33K Mar 10 09:00 orrors.ipynb\r\n",
      "-rw-r--r--   1 bono  staff    17K Mar 10 09:02 cohesion.ipynb\r\n",
      "drwxr-xr-x  32 bono  staff   1.0K Mar 10 09:02 \u001b[34m.\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   6.9G Mar 10 09:02 1800.data.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls -larth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbbdca",
   "metadata": {},
   "source": [
    "### DELETE ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08531053",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './644sample/644.data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./644sample/644.data.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m      3\u001b[0m     selected \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n",
      "File \u001b[0;32m~/miniforge3/envs/doubt/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './644sample/644.data.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./644sample/644.data.pickle', 'rb') as handle:\n",
    "    selected = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ecdbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae2df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "688*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3194b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 ms, sys: 1.83 ms, total: 5.05 ms\n",
      "Wall time: 5.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selected_pids = set([s['pid'] for s in selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b627c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('selected_pids.688.pickle', 'wb') as handle:\n",
    "    pickle.dump(selected_pids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a006d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3810400\r\n",
      "-rw-r--r--@  1 bono  staff    15M May 14  2024 turl_test_2k_prompts_50.jsonl\r\n",
      "-rw-r--r--   1 bono  staff    17B Feb 10 10:37 README.md\r\n",
      "-rwx------@  1 bono  staff   4.8K Feb 19 14:05 \u001b[31mrunner.py\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   137M Feb 19 16:32 gemma-2-2b-it.3892595837.pickle\r\n",
      "-rw-r--r--@  1 bono  staff   5.0K Feb 20 09:23 prompt100.py\r\n",
      "-rw-r--r--   1 bono  staff    16M Feb 20 20:07 tablellama.preprocessed.pickle\r\n",
      "-rw-r--r--@  1 bono  staff   5.2K Feb 20 21:04 prompt100tablellama.py\r\n",
      "-rw-r--r--   1 bono  staff   117M Feb 22 09:11 gemma-2-9b-it-4bit.3246737286.pickle\r\n",
      "drwxr-xr-x   4 bono  staff   128B Feb 27 07:56 \u001b[34mmirror\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 11 bono  staff   352B Feb 27 08:19 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 bono  staff   5.3K Mar  2 14:55 prompt100gemmalocal.py\r\n",
      "-rw-r--r--   1 bono  staff   222K Mar  4 13:37 jensension.ipynb\r\n",
      "drwxr-xr-x   4 bono  staff   128B Mar  5 20:03 \u001b[34molder tablellama\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  12 bono  staff   384B Mar  6 15:38 \u001b[34mtablellama10runs\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   450K Mar  6 16:03 tablellama-multipass.ipynb\r\n",
      "-rw-r--r--   1 bono  staff   450K Mar  6 16:09 tablellama-plot copy.ipynb\r\n",
      "-rw-r--r--@  1 bono  staff   6.2K Mar  6 19:31 prompt_wip.py\r\n",
      "-rw-r--r--@  1 bono  staff   6.2K Mar  6 19:31 prompt_wip sel.py\r\n",
      "-rw-r--r--   1 bono  staff   726K Mar  7 15:06 logits-tablellama.ipynb\r\n",
      "drwxr-xr-x   2 bono  staff    64B Mar  8 14:54 \u001b[34mtest\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   127M Mar 10 08:46 1800.pickle\r\n",
      "-rw-rw----@  1 bono  staff   4.0M Mar 10 10:26 delme.xlsx\r\n",
      "drwxr-xr-x   9 bono  staff   288B Mar 10 16:41 \u001b[34mpdf\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  10 bono  staff   320B Mar 11 09:07 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   892K Mar 11 10:52 tablellama-classifier.ipynb\r\n",
      "drwxr-xr-x   4 bono  staff   128B Mar 11 15:24 \u001b[34m644sample\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   1.0G Mar 11 15:27 preprocessed.pickle\r\n",
      "-rw-r--r--   1 bono  staff   1.4M Mar 11 15:28 tablellama-plot.ipynb\r\n",
      "-rw-r--r--   1 bono  staff   390M Mar 11 16:16 cohesion.pickle\r\n",
      "-rw-r--r--   1 bono  staff   114K Mar 11 16:25 cohesion.ipynb\r\n",
      "drwxr-xr-x  16 bono  staff   512B Mar 11 16:36 \u001b[34m.git\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 bono  staff    10K Mar 11 17:49 .DS_Store\r\n",
      "-rw-r--r--   1 bono  staff     0B Mar 11 17:52 selected_pids.644.pickle\r\n",
      "-rw-r--r--   1 bono  staff    36K Mar 11 17:56 select_errors_from_1800.ipynb\r\n",
      "drwxr-xr-x  36 bono  staff   1.1K Mar 11 17:56 \u001b[34m.\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 bono  staff   1.9K Mar 11 18:12 selected_pids.688.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls -larth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297c3fc",
   "metadata": {},
   "source": [
    "### debug (transition scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7115aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d800d12cf74090b3b61becb532b77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "# run params\n",
    "temperature=1.0\n",
    "top_p=0.9\n",
    "max_new_tokens=128\n",
    "use_cache=True\n",
    "device = \"mps\"\n",
    "\n",
    "model_name = \"osunlp/TableLlama\"\n",
    "\n",
    "# load inputs\n",
    "file_path = \"turl_test_2k_prompts_50.jsonl\"\n",
    "device = torch.device(device)\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    prompts = [json.loads(line) for line in f]\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n",
    "model.resize_token_embeddings(32001)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=orig_ctx_len, padding_side=\"left\", use_fast=False)\n",
    "model.eval()\n",
    "\n",
    "# build prompts\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_seg}\\n\\n### Question:\\n{question}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def generate_prompt(instruction, question, input_seg=None):\n",
    "    question += \" Answer with just a candidate, selected from the provided referent entity candidates list, and nothing else. The selected candidate must be reported verbatim from the list provided as input. Each candidate in the list is enclosed between < and > and reports [DESC] and [TYPE] information.\"\n",
    "    if input_seg:\n",
    "        return PROMPT_DICT[\"prompt_input\"].format(instruction=instruction, input_seg=input_seg, question=question)\n",
    "    else:\n",
    "        return PROMPT_DICT[\"prompt_no_input\"].format(instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fc7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = prompts[742] # 742 is shortest\n",
    "p = prompts[840] # average joe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5854033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 498 ms, total: 719 ms\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = generate_prompt(p[\"instruction\"], p[\"question\"], p[\"input\"])\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    pre_output = model(**inputs, use_cache=use_cache)\n",
    "pre_output = pre_output.logits.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb64b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 945 ms, total: 2.82 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "post_output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True,\n",
    "    output_logits=True,\n",
    "    use_cache=use_cache\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539779e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_scores = model.compute_transition_scores(post_output.sequences, post_output.scores, normalize_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772738ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1094]), 21, torch.Size([1, 32001]), torch.Size([1, 21]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_output.sequences.shape, len(post_output.scores), post_output.scores[0].shape, transition_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a9695f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32001])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_output.scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0d2817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f687ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihoods = [score.item() for score in transition_scores[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5af0080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3557f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores_s = model.compute_transition_scores(post_output.sequences, post_output.scores, normalize_logits=True)\n",
    "log_likelihoods_s = [score.item() for score in transition_scores[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e079b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f264bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.768370445162873e-07,\n",
       " -0.09085541218519211,\n",
       " -0.10185058414936066,\n",
       " -4.768370445162873e-07,\n",
       " -1.1920928244535389e-07,\n",
       " -2.407998726994265e-05,\n",
       " -0.0023836076725274324,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.022649873048067093,\n",
       " -0.007525428663939238,\n",
       " -9.536738616588991e-07,\n",
       " -3.576278118089249e-07,\n",
       " 0.0,\n",
       " -2.3841855067985307e-07,\n",
       " 0.0,\n",
       " -3.2186455882765586e-06,\n",
       " -7.867782187531702e-06,\n",
       " -5.960462772236497e-07,\n",
       " -1.1920928244535389e-07,\n",
       " 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores_l = model.compute_transition_scores(post_output.sequences, post_output.logits, normalize_logits=True)\n",
    "log_likelihoods_l = [score.item() for score in transition_scores[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fad576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7684e-07, -9.0855e-02, -1.0185e-01, -4.7684e-07, -1.1921e-07,\n",
       "         -2.4080e-05, -2.3836e-03,  0.0000e+00,  0.0000e+00, -2.2650e-02,\n",
       "         -7.5254e-03, -9.5367e-07, -3.5763e-07,  0.0000e+00, -2.3842e-07,\n",
       "          0.0000e+00, -3.2186e-06, -7.8678e-06, -5.9605e-07, -1.1921e-07,\n",
       "          0.0000e+00]], device='mps:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doubt",
   "language": "python",
   "name": "doubt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
