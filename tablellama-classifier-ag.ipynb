{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7139c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bono/miniforge3/envs/ag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "import xgboost\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb8d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed.pickle', 'rb') as handle:\n",
    "    mydict = pickle.load(handle)\n",
    "    \n",
    "truth = mydict['truth']\n",
    "segments = mydict['segments']\n",
    "m = mydict['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220b6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = m.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91630974",
   "metadata": {},
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631f003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.run.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb77e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['preamble', 'instruction', 'input', 'question', 'postilla',\n",
       "       'generated'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.segment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0f1c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum number of generated tokens\n",
    "mm[(mm.segment=='postilla')].groupby('pid').tokzero.max().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5b33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beginning of generation\n",
    "ds = mm[(mm.segment=='postilla')][['run', 'pid', 'tokzero', 'shape', 'true_ent', 'maxp']]\n",
    "\n",
    "ds = ds.pivot(index=['run', 'pid'], columns='tokzero', values=['maxp', 'true_ent']).reset_index()\n",
    "ds.columns = [''.join([str(c) for c in col]).strip() for col in ds.columns.values]\n",
    "ds = ds.merge(truth, on=['run', 'pid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86194cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "True     4977\n",
       "False    1903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6dc5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ds.correct\n",
    "pids = ds.pid\n",
    "X = ds.drop(columns=['run', 'pid', 'correct', 'hallucinated'])\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "pids_res = pids[y_res.index]\n",
    "\n",
    "X_res.columns = ['postilla_'+col for col in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83e581",
   "metadata": {},
   "source": [
    "### beginning of generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2303cfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          9\n",
       "1         10\n",
       "2         12\n",
       "3         14\n",
       "7         23\n",
       "        ... \n",
       "2707    1677\n",
       "1194    1342\n",
       "1037     896\n",
       "2272     530\n",
       "134      355\n",
       "Name: pid, Length: 3806, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pids_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819ef1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "# just get the first group\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X_res, y_res, pids_res)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # print(f\"  Train: index={train_index}, group={pids_res.iloc[train_index]}\")\n",
    "    # print(f\"  Test:  index={test_index}, group={pids_res.iloc[test_index]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b010ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_res.iloc[train_index]\n",
    "y_train = y_res.iloc[train_index]\n",
    "pids_train = pids_res.iloc[train_index]\n",
    "\n",
    "X_test = X_res.iloc[test_index]\n",
    "y_test = y_res.iloc[test_index]\n",
    "pids_test = pids_res.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b601e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be true\n",
    "len(set(pids_train.values) & set(pids_test.values))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa88c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98ac872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/n2krf1q970d6cfl43cjq73s80000gn/T/ipykernel_74766/1796950693.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train['label'] = y_train\n",
      "/var/folders/kn/n2krf1q970d6cfl43cjq73s80000gn/T/ipykernel_74766/1796950693.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['label'] = y_train\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"tablellama-high\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       11.57 GB / 64.00 GB (18.1%)\n",
      "Disk Space Avail:   71.55 GB / 926.35 GB (7.7%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "2025-03-15 10:53:16,669\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-03-15 10:53:18,134\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/bono/Library/CloudStorage/OneDrive-PolitecnicodiMilano/work/prin/llm-uncertainty/tablellama-high/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m /Users/bono/miniforge3/envs/ag/lib/python3.11/site-packages/autogluon/core/utils/utils.py:428: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m   train_data[label] = y_train\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m /Users/bono/miniforge3/envs/ag/lib/python3.11/site-packages/autogluon/core/utils/utils.py:429: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m   test_data[label] = y_test\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Beginning AutoGluon training ... Time limit = 898s\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m AutoGluon will save models to \"/Users/bono/Library/CloudStorage/OneDrive-PolitecnicodiMilano/work/prin/llm-uncertainty/tablellama-high/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Train Data Rows:    2705\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Train Data Columns: 130\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Label Column:       label\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tAvailable Memory:                    11909.28 MB\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.68 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tUseless Original Features (Count: 1): ['postilla_maxp26']\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\t('float', []) : 129 | ['postilla_maxp0', 'postilla_maxp1', 'postilla_maxp2', 'postilla_maxp3', 'postilla_maxp4', ...]\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\t('float', [])     : 128 | ['postilla_maxp0', 'postilla_maxp1', 'postilla_maxp2', 'postilla_maxp3', 'postilla_maxp4', ...]\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t\t('int', ['bool']) :   1 | ['postilla_maxp50']\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t129 features in original data used to generate 129 features in processed data.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTrain Data (Processed) Memory Usage: 2.64 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 598.20s of the 897.52s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8329\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 597.23s of the 896.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8721\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 597.19s of the 896.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8736\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 592.32s of the 891.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.33%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8736\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 585.10s of the 884.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8717\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 584.17s of the 883.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.871\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 583.34s of the 882.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8717\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t18.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 562.81s of the 862.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8699\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 562.20s of the 861.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.871\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 561.63s of the 860.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_ray_fit pid=74886)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t4.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 555.01s of the 854.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.875\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t8.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 544.65s of the 843.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.881\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 531.87s of the 831.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.90%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8747\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t14.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 514.95s of the 814.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8762\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t21.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 491.25s of the 790.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8773\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t10.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 479.34s of the 778.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8647\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 471.69s of the 771.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_ray_fit pid=74953)\u001b[0m No improvement since epoch 19: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8736\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 458.37s of the 757.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.76%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8739\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t160.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 295.79s of the 595.11s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=74952)\u001b[0m No improvement since epoch 20: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=74981)\u001b[0m [1000]\tvalid_set's binary_error: 0.136095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8662\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 291.16s of the 590.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8784\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t18.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.19s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 270.87s of the 570.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.24%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8717\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t12.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 256.53s of the 555.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8677\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 255.56s of the 554.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8725\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 242.60s of the 541.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8599\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 237.38s of the 536.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.80%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8691\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t47.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 187.30s of the 486.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.868\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 184.13s of the 483.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.87%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8758\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t4.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 177.10s of the 476.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_ray_fit pid=75058)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8706\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t6.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 168.70s of the 468.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.62%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8717\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 161.62s of the 460.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8758\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t14.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 144.94s of the 444.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8743\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 140.71s of the 440.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8728\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 127.32s of the 426.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8736\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t17.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 108.29s of the 407.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8677\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 95.32s of the 394.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.01%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8739\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t8.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 84.98s of the 384.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8621\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 84.01s of the 383.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8739\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t13.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 68.54s of the 367.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_ray_fit pid=75150)\u001b[0m No improvement since epoch 11: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t6.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 59.97s of the 359.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8773\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t4.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 53.32s of the 352.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\u001b[36m(_ray_fit pid=75146)\u001b[0m No improvement since epoch 25: early stopping\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8706\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t6.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 45.19s of the 344.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8481\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 39.69s of the 339.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\u001b[36m(_ray_fit pid=75184)\u001b[0m \tRan out of time, early stopping on iteration 617.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t31.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 6.09s of the 305.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8625\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t4.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=75183)\u001b[0m \tRan out of time, early stopping on iteration 621.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 299.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.6, 'LightGBMLarge_BAG_L1': 0.2, 'LightGBM_r188_BAG_L1': 0.2}\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8817\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 298.92s of the 298.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=75222)\u001b[0m [1000]\tvalid_set's binary_error: 0.0532544\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9571\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 293.16s of the 293.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=75232)\u001b[0m [1000]\tvalid_set's binary_error: 0.056213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9523\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 286.59s of the 286.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9375\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 285.76s of the 285.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9372\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 285.04s of the 284.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.942\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t32.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 251.38s of the 251.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9379\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 250.82s of the 250.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.939\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 250.32s of the 250.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9431\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 245.54s of the 245.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.72%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9468\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 240.03s of the 239.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9323\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 226.84s of the 226.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.07%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9434\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t7.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 218.45s of the 218.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.62%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9416\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t25.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 191.26s of the 191.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9604\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t13.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 176.48s of the 176.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=75312)\u001b[0m [1000]\tvalid_set's binary_error: 0.0739645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9471\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t7.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 167.44s of the 167.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9608\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t8.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 157.96s of the 157.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.07%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9427\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t117.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 38.62s of the 38.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8802\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 36.68s of the 36.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.925\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t17.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 17.89s of the 17.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.89%)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9438\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_r191_BAG_L2': 0.632, 'LightGBM_BAG_L2': 0.105, 'NeuralNetFastAI_BAG_L2': 0.105, 'NeuralNetTorch_r79_BAG_L2': 0.105, 'ExtraTreesEntr_BAG_L2': 0.053}\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.9623\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m AutoGluon training complete, total runtime = 892.92s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 250.2 rows/s (339 batch size)\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStopping at the best epoch learned earlier - 18.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t9.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t7.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r96_BAG_L1_FULL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t13.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tStopping at the best epoch learned earlier - 18.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t4.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t12.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t8.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t6.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTrees_r172_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.6, 'LightGBMLarge_BAG_L1': 0.2, 'LightGBM_r188_BAG_L1': 0.2}\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t3.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t1.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t11.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t5.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t23.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t6.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t9.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t19.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t2.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_r191_BAG_L2': 0.632, 'LightGBM_BAG_L2': 0.105, 'NeuralNetFastAI_BAG_L2': 0.105, 'NeuralNetTorch_r79_BAG_L2': 0.105, 'ExtraTreesEntr_BAG_L2': 0.053}\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t0.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Refit complete, total runtime = 201.18s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2705 rows).\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m \t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/bono/Library/CloudStorage/OneDrive-PolitecnicodiMilano/work/prin/llm-uncertainty/tablellama-high/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=74806)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_r69_BAG_L1_FULL       0.867257   0.873937    accuracy        0.002831            NaN   0.795872                 0.002831                     NaN           0.795872            1       True         37\n",
      "1          LightGBM_r131_BAG_L1_FULL       0.867257   0.864695    accuracy        0.003559            NaN   1.554048                 0.003559                     NaN           1.554048            1       True         16\n",
      "2     NeuralNetTorch_r30_BAG_L1_FULL       0.867257   0.875786    accuracy        0.021043            NaN  12.033967                 0.021043                     NaN          12.033967            1       True         30\n",
      "3         ExtraTreesGini_BAG_L1_FULL       0.867257   0.869871    accuracy        0.036434       0.127860   0.446848                 0.036434                0.127860           0.446848            1       True          8\n",
      "4         ExtraTreesEntr_BAG_L1_FULL       0.867257   0.870980    accuracy        0.037171       0.119679   0.422151                 0.037171                0.119679           0.422151            1       True          9\n",
      "5       RandomForestGini_BAG_L1_FULL       0.867257   0.871719    accuracy        0.038457       0.134705   0.760263                 0.038457                0.134705           0.760263            1       True          5\n",
      "6      RandomForest_r195_BAG_L1_FULL       0.867257   0.868022    accuracy        0.050695       0.105549   3.048144                 0.050695                0.105549           3.048144            1       True         26\n",
      "7           CatBoost_r70_BAG_L1_FULL       0.864307   0.873198    accuracy        0.004624            NaN   1.695922                 0.004624                     NaN           1.695922            1       True         42\n",
      "8         ExtraTrees_r42_BAG_L1_FULL       0.864307   0.867652    accuracy        0.040039       0.140364   0.801341                 0.040039                0.140364           0.801341            1       True         22\n",
      "9         ExtraTreesGini_BAG_L2_FULL       0.864307   0.937893    accuracy        0.302274            NaN  41.825567                 0.037233                0.109780           0.418224            2       True         50\n",
      "10           XGBoost_r89_BAG_L1_FULL       0.861357   0.871719    accuracy        0.005268            NaN   0.480948                 0.005268                     NaN           0.480948            1       True         29\n",
      "11              LightGBM_BAG_L1_FULL       0.861357   0.873567    accuracy        0.005490            NaN   2.244400                 0.005490                     NaN           2.244400            1       True          4\n",
      "12              LightGBM_BAG_L2_FULL       0.861357   0.952311    accuracy        0.271823            NaN  45.304102                 0.006782                     NaN           3.896759            2       True         46\n",
      "13              CatBoost_BAG_L1_FULL       0.858407   0.871719    accuracy        0.004702            NaN   0.947420                 0.004702                     NaN           0.947420            1       True          7\n",
      "14       NeuralNetFastAI_BAG_L1_FULL       0.858407   0.873198    accuracy        0.009518            NaN   1.604229                 0.009518                     NaN           1.604229            1       True         10\n",
      "15          XGBoost_r194_BAG_L1_FULL       0.858407   0.873937    accuracy        0.012945            NaN   0.545990                 0.012945                     NaN           0.545990            1       True         35\n",
      "16    NeuralNetTorch_r86_BAG_L1_FULL       0.858407   0.872828    accuracy        0.017976            NaN   8.034563                 0.017976                     NaN           8.034563            1       True         32\n",
      "17        ExtraTreesEntr_BAG_L2_FULL       0.858407   0.939002    accuracy        0.301370            NaN  41.778065                 0.036329                0.099717           0.370722            2       True         51\n",
      "18         LightGBM_r161_BAG_L1_FULL       0.855457   0.870610    accuracy        0.003786            NaN   1.560309                 0.003786                     NaN           1.560309            1       True         40\n",
      "19         CatBoost_r177_BAG_L1_FULL       0.855457   0.876155    accuracy        0.003981            NaN   1.109016                 0.003981                     NaN           1.109016            1       True         14\n",
      "20         CatBoost_r137_BAG_L1_FULL       0.855457   0.872458    accuracy        0.004460            NaN   0.764357                 0.004460                     NaN           0.764357            1       True         23\n",
      "21          CatBoost_r50_BAG_L1_FULL       0.855457   0.873567    accuracy        0.005017            NaN   1.419582                 0.005017                     NaN           1.419582            1       True         33\n",
      "22            LightGBMXT_BAG_L1_FULL       0.855457   0.873567    accuracy        0.005018            NaN   2.010271                 0.005018                     NaN           2.010271            1       True          3\n",
      "23           CatBoost_r9_BAG_L1_FULL       0.855457   0.873937    accuracy        0.006329            NaN   7.407447                 0.006329                     NaN           7.407447            1       True         18\n",
      "24               XGBoost_BAG_L1_FULL       0.855457   0.875046    accuracy        0.006603            NaN   1.055491                 0.006603                     NaN           1.055491            1       True         11\n",
      "25        KNeighborsDist_BAG_L1_FULL       0.855457   0.872089    accuracy        0.012991       0.022386   0.008393                 0.012991                0.022386           0.008393            1       True          2\n",
      "26    NeuralNetTorch_r22_BAG_L1_FULL       0.855457   0.878373    accuracy        0.017378            NaN  13.016389                 0.017378                     NaN          13.016389            1       True         20\n",
      "27    NeuralNetTorch_r79_BAG_L1_FULL       0.855457   0.877264    accuracy        0.019574            NaN   9.160973                 0.019574                     NaN           9.160973            1       True         15\n",
      "28      RandomForestEntr_BAG_L1_FULL       0.855457   0.870980    accuracy        0.034587       0.134496   0.668501                 0.034587                0.134496           0.668501            1       True          6\n",
      "29          LightGBM_r96_BAG_L2_FULL       0.855457   0.880222    accuracy        0.267204            NaN  41.563062                 0.002163                     NaN           0.155719            2       True         61\n",
      "30               XGBoost_BAG_L2_FULL       0.855457   0.946765    accuracy        0.272100            NaN  42.531168                 0.007059                     NaN           1.123825            2       True         53\n",
      "31           CatBoost_r9_BAG_L2_FULL       0.855457   0.942699    accuracy        0.272145            NaN  51.215186                 0.007104                     NaN           9.807843            2       True         60\n",
      "32         LightGBM_r130_BAG_L1_FULL       0.852507   0.874307    accuracy        0.004381            NaN   1.357583                 0.004381                     NaN           1.357583            1       True         31\n",
      "33           XGBoost_r33_BAG_L1_FULL       0.852507   0.871719    accuracy        0.004980            NaN   0.522877                 0.004980                     NaN           0.522877            1       True         21\n",
      "34         LightGBM_r188_BAG_L1_FULL       0.852507   0.875786    accuracy        0.008030            NaN   2.368042                 0.008030                     NaN           2.368042            1       True         27\n",
      "35    NeuralNetTorch_r14_BAG_L1_FULL       0.852507   0.877264    accuracy        0.015709            NaN   2.849069                 0.015709                     NaN           2.849069            1       True         39\n",
      "36  NeuralNetFastAI_r145_BAG_L1_FULL       0.852507   0.870610    accuracy        0.017326            NaN   4.507397                 0.017326                     NaN           4.507397            1       True         28\n",
      "37          WeightedEnsemble_L2_FULL       0.852507   0.881701    accuracy        0.031900            NaN  11.707277                 0.000852                     NaN           0.095011            2       True         44\n",
      "38       ExtraTrees_r172_BAG_L1_FULL       0.852507   0.862107    accuracy        0.034672       0.113832   0.835168                 0.034672                0.113832           0.835168            1       True         36\n",
      "39            LightGBMXT_BAG_L2_FULL       0.852507   0.957116    accuracy        0.273452            NaN  44.891346                 0.008411                     NaN           3.484003            2       True         45\n",
      "40  NeuralNetFastAI_r191_BAG_L2_FULL       0.852507   0.960813    accuracy        0.274524            NaN  44.083011                 0.009483                     NaN           2.675668            2       True         59\n",
      "41        NeuralNetTorch_BAG_L2_FULL       0.852507   0.932348    accuracy        0.281966            NaN  53.035755                 0.016925                     NaN          11.628412            2       True         54\n",
      "42          LightGBM_r96_BAG_L1_FULL       0.849558   0.866174    accuracy        0.006219            NaN   1.956641                 0.006219                     NaN           1.956641            1       True         19\n",
      "43         LightGBMLarge_BAG_L1_FULL       0.849558   0.874677    accuracy        0.006274            NaN   3.937316                 0.006274                     NaN           3.937316            1       True         13\n",
      "44          CatBoost_r13_BAG_L1_FULL       0.849558   0.869131    accuracy        0.007030            NaN   1.334115                 0.007030                     NaN           1.334115            1       True         25\n",
      "45        NeuralNetTorch_BAG_L1_FULL       0.849558   0.880961    accuracy        0.016744            NaN   5.306908                 0.016744                     NaN           5.306908            1       True         12\n",
      "46      RandomForestEntr_BAG_L2_FULL       0.849558   0.937153    accuracy        0.298258            NaN  41.996589                 0.033217                0.104941           0.589246            2       True         48\n",
      "47      RandomForestGini_BAG_L2_FULL       0.849558   0.937523    accuracy        0.300661            NaN  42.111693                 0.035620                0.101427           0.704350            2       True         47\n",
      "48         CatBoost_r177_BAG_L2_FULL       0.846608   0.941590    accuracy        0.269513            NaN  43.812752                 0.004472                     NaN           2.405409            2       True         56\n",
      "49              CatBoost_BAG_L2_FULL       0.846608   0.941959    accuracy        0.271177            NaN  44.261870                 0.006136                     NaN           2.854527            2       True         49\n",
      "50           XGBoost_r33_BAG_L2_FULL       0.846608   0.943808    accuracy        0.271933            NaN  43.729817                 0.006892                     NaN           2.322474            2       True         63\n",
      "51          WeightedEnsemble_L3_FULL       0.846608   0.962292    accuracy        0.348418            NaN  73.537241                 0.000970                     NaN           0.091277            3       True         64\n",
      "52       NeuralNetFastAI_BAG_L2_FULL       0.840708   0.943068    accuracy        0.274212            NaN  43.028544                 0.009171                     NaN           1.621201            2       True         52\n",
      "53         LightGBM_r131_BAG_L2_FULL       0.840708   0.947135    accuracy        0.274484            NaN  47.704127                 0.009443                     NaN           6.296784            2       True         58\n",
      "54    NeuralNetTorch_r79_BAG_L2_FULL       0.837758   0.960444    accuracy        0.285683            NaN  64.881614                 0.020642                     NaN          23.474271            2       True         57\n",
      "55    NeuralNetTorch_r22_BAG_L2_FULL       0.828909   0.924954    accuracy        0.282386            NaN  60.490628                 0.017345                     NaN          19.083285            2       True         62\n",
      "56         LightGBMLarge_BAG_L2_FULL       0.825959   0.943438    accuracy        0.270796            NaN  46.473681                 0.005755                     NaN           5.066338            2       True         55\n",
      "57        KNeighborsUnif_BAG_L1_FULL       0.808260   0.832902    accuracy        0.007032       0.041514   0.008501                 0.007032                0.041514           0.008501            1       True          1\n",
      "58   NeuralNetFastAI_r11_BAG_L1_FULL       0.758112   0.867652    accuracy        0.014239            NaN   6.086219                 0.014239                     NaN           6.086219            1       True         34\n",
      "59  NeuralNetFastAI_r103_BAG_L1_FULL       0.740413   0.873198    accuracy        0.009437            NaN   1.986314                 0.009437                     NaN           1.986314            1       True         38\n",
      "60  NeuralNetFastAI_r191_BAG_L1_FULL       0.737463   0.873567    accuracy        0.010567            NaN   2.741858                 0.010567                     NaN           2.741858            1       True         17\n",
      "61  NeuralNetFastAI_r102_BAG_L1_FULL       0.578171   0.859889    accuracy        0.009062            NaN   0.432296                 0.009062                     NaN           0.432296            1       True         24\n",
      "62  NeuralNetFastAI_r143_BAG_L1_FULL       0.510324   0.848059    accuracy        0.008720            NaN   0.592715                 0.008720                     NaN           0.592715            1       True         41\n",
      "63  NeuralNetFastAI_r156_BAG_L1_FULL       0.501475   0.862477    accuracy        0.006212            NaN   0.401712                 0.006212                     NaN           0.401712            1       True         43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1099s\t = DyStack   runtime |\t2501s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2501s\n",
      "AutoGluon will save models to \"/Users/bono/Library/CloudStorage/OneDrive-PolitecnicodiMilano/work/prin/llm-uncertainty/tablellama-high\"\n",
      "Train Data Rows:    3044\n",
      "Train Data Columns: 130\n",
      "Label Column:       label\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13814.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['postilla_maxp26']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 129 | ['postilla_maxp0', 'postilla_maxp1', 'postilla_maxp2', 'postilla_maxp3', 'postilla_maxp4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 128 | ['postilla_maxp0', 'postilla_maxp1', 'postilla_maxp2', 'postilla_maxp3', 'postilla_maxp4', ...]\n",
      "\t\t('int', ['bool']) :   1 | ['postilla_maxp50']\n",
      "\t0.1s = Fit runtime\n",
      "\t129 features in original data used to generate 129 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2500.94s of the 2500.94s of remaining time.\n",
      "\t0.8407\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2500.86s of the 2500.86s of remaining time.\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2500.82s of the 2500.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t2.25s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2495.66s of the 2495.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t4.2s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2490.44s of the 2490.43s of remaining time.\n",
      "\t0.8689\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2489.84s of the 2489.84s of remaining time.\n",
      "\t0.8679\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2489.25s of the 2489.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.47%)\n",
      "\t0.8722\t = Validation score   (accuracy)\n",
      "\t18.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2469.71s of the 2469.71s of remaining time.\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2469.29s of the 2469.28s of remaining time.\n",
      "\t0.8686\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2468.87s of the 2468.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2464.15s of the 2464.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.57%)\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t5.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2456.71s of the 2456.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8778\t = Validation score   (accuracy)\n",
      "\t5.99s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2449.67s of the 2449.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.81%)\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t13.84s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2434.74s of the 2434.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t17.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2416.72s of the 2416.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t7.7s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2407.99s of the 2407.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.8699\t = Validation score   (accuracy)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2403.31s of the 2403.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t10.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2392.21s of the 2392.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.52%)\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t133.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2257.03s of the 2257.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8653\t = Validation score   (accuracy)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2253.72s of the 2253.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8761\t = Validation score   (accuracy)\n",
      "\t14.41s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2238.14s of the 2238.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.88%)\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t13.37s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 2223.59s of the 2223.59s of remaining time.\n",
      "\t0.8666\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2222.91s of the 2222.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8702\t = Validation score   (accuracy)\n",
      "\t8.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 2213.17s of the 2213.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8584\t = Validation score   (accuracy)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2209.38s of the 2209.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.65%)\n",
      "\t0.8679\t = Validation score   (accuracy)\n",
      "\t49.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 2158.46s of the 2158.45s of remaining time.\n",
      "\t0.8679\t = Validation score   (accuracy)\n",
      "\t2.38s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2155.95s of the 2155.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.80%)\n",
      "\t0.8696\t = Validation score   (accuracy)\n",
      "\t3.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 2151.10s of the 2151.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t5.61s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 2144.48s of the 2144.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.57%)\n",
      "\t0.8722\t = Validation score   (accuracy)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 2140.00s of the 2139.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t13.84s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 2125.05s of the 2125.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.61%)\n",
      "\t0.8706\t = Validation score   (accuracy)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 2121.28s of the 2121.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 2113.88s of the 2113.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t12.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 2100.25s of the 2100.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.867\t = Validation score   (accuracy)\n",
      "\t8.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 2090.61s of the 2090.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t5.37s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 2083.77s of the 2083.77s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 2083.07s of the 2083.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t14.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 2068.06s of the 2068.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t5.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 2061.34s of the 2061.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8778\t = Validation score   (accuracy)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 2056.62s of the 2056.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.59%)\n",
      "\t0.8686\t = Validation score   (accuracy)\n",
      "\t6.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 2048.65s of the 2048.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8509\t = Validation score   (accuracy)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 2044.43s of the 2044.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8706\t = Validation score   (accuracy)\n",
      "\t45.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1997.56s of the 1997.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 1992.98s of the 1992.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 1988.19s of the 1988.18s of remaining time.\n",
      "\t0.8673\t = Validation score   (accuracy)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 1985.72s of the 1985.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.80%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t24.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1959.99s of the 1959.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t5.7s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1953.02s of the 1953.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8722\t = Validation score   (accuracy)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 1946.41s of the 1946.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.56%)\n",
      "\t0.8706\t = Validation score   (accuracy)\n",
      "\t13.49s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 1931.81s of the 1931.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\t0.8686\t = Validation score   (accuracy)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1928.22s of the 1928.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 1910.42s of the 1910.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.50%)\n",
      "\t0.8702\t = Validation score   (accuracy)\n",
      "\t44.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 1864.57s of the 1864.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t4.59s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 1858.98s of the 1858.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t4.94s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 1852.68s of the 1852.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t7.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 1844.70s of the 1844.69s of remaining time.\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 1844.19s of the 1844.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.08%)\n",
      "\t0.867\t = Validation score   (accuracy)\n",
      "\t5.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 1837.98s of the 1837.97s of remaining time.\n",
      "\t0.8633\t = Validation score   (accuracy)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 1835.01s of the 1835.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t7.46s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 1826.54s of the 1826.53s of remaining time.\n",
      "\t0.8423\t = Validation score   (accuracy)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 1824.82s of the 1824.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.867\t = Validation score   (accuracy)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 1822.45s of the 1822.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8807\t = Validation score   (accuracy)\n",
      "\t16.66s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 1804.67s of the 1804.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.46%)\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t114.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 1688.99s of the 1688.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.7326\t = Validation score   (accuracy)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 1684.73s of the 1684.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t6.49s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 1676.75s of the 1676.75s of remaining time.\n",
      "\t0.8499\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 1676.16s of the 1676.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8137\t = Validation score   (accuracy)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 1672.10s of the 1672.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 1667.19s of the 1667.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.77%)\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 1663.72s of the 1663.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t8.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 1653.76s of the 1653.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t6.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 1645.87s of the 1645.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t8.29s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 1636.40s of the 1636.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8794\t = Validation score   (accuracy)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 1631.48s of the 1631.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.86%)\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t23.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r178_BAG_L1 ... Training model for up to 1606.81s of the 1606.80s of remaining time.\n",
      "\t0.863\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L1 ... Training model for up to 1606.19s of the 1606.18s of remaining time.\n",
      "\t0.8686\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 1605.64s of the 1605.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\t0.8633\t = Validation score   (accuracy)\n",
      "\t6.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 1597.90s of the 1597.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 1590.41s of the 1590.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t4.17s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 1585.24s of the 1585.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.33%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t12.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r15_BAG_L1 ... Training model for up to 1571.76s of the 1571.76s of remaining time.\n",
      "\t0.8633\t = Validation score   (accuracy)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 1569.19s of the 1569.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.24%)\n",
      "\t0.8693\t = Validation score   (accuracy)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 1564.62s of the 1564.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\t0.8719\t = Validation score   (accuracy)\n",
      "\t4.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 1559.12s of the 1559.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8689\t = Validation score   (accuracy)\n",
      "\t3.7s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 1554.11s of the 1554.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t12.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 1540.07s of the 1540.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8719\t = Validation score   (accuracy)\n",
      "\t11.59s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 1527.15s of the 1527.15s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.38%)\n",
      "\t0.8696\t = Validation score   (accuracy)\n",
      "\t5.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 1520.78s of the 1520.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t3.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 1516.38s of the 1516.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.89%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t58.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 1456.55s of the 1456.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8765\t = Validation score   (accuracy)\n",
      "\t6.13s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r197_BAG_L1 ... Training model for up to 1449.17s of the 1449.17s of remaining time.\n",
      "\t0.8683\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 1448.34s of the 1448.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t15.63s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 1431.70s of the 1431.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t2.56s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForest_r16_BAG_L1 ... Training model for up to 1427.85s of the 1427.84s of remaining time.\n",
      "\t0.867\t = Validation score   (accuracy)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 1424.25s of the 1424.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t3.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L1 ... Training model for up to 1419.37s of the 1419.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.90%)\n",
      "\t0.8689\t = Validation score   (accuracy)\n",
      "\t26.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 1391.46s of the 1391.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t13.95s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 1376.21s of the 1376.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8656\t = Validation score   (accuracy)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L1 ... Training model for up to 1371.74s of the 1371.73s of remaining time.\n",
      "\t0.865\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 1370.88s of the 1370.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t13.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 1356.17s of the 1356.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8676\t = Validation score   (accuracy)\n",
      "\t6.51s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L1 ... Training model for up to 1348.34s of the 1348.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t8.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r198_BAG_L1 ... Training model for up to 1338.49s of the 1338.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\t0.8706\t = Validation score   (accuracy)\n",
      "\t13.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 1324.01s of the 1324.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t3.12s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 1319.53s of the 1319.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8788\t = Validation score   (accuracy)\n",
      "\t4.78s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_r95_BAG_L1 ... Training model for up to 1313.33s of the 1313.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\t0.8719\t = Validation score   (accuracy)\n",
      "\t5.02s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L1 ... Training model for up to 1307.17s of the 1307.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.82%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t5.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L1 ... Training model for up to 1300.55s of the 1300.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t2.51s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 1296.63s of the 1296.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8696\t = Validation score   (accuracy)\n",
      "\t16.03s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 1279.49s of the 1279.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t10.99s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1267.40s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r143_BAG_L1': 1.0}\n",
      "\t0.8807\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1233.75s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2785.6 rows/s (381 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.66s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t1.36s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.67s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t6.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t6.73s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t0.78s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\t8.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t1.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t3.11s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t5.11s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t1.75s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\t16.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t1.66s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t0.8s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t2.43s\t = Training   runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.38s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t1.58s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t6.91s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1_FULL ...\n",
      "\t19.74s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t1.59s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1_FULL ...\n",
      "\t4.91s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\t1.02s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t6.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\t0.53s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\t1.08s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t2.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1_FULL ...\n",
      "\t2.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\t1.66s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.76s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\t2.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.44s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\t1.59s\t = Training   runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\t1.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t6.22s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1_FULL ...\n",
      "\t4.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\t1.37s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\t1.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1_FULL ...\n",
      "\t16.69s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r86_BAG_L1_FULL ...\n",
      "\t1.66s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t1.67s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1_FULL ...\n",
      "\t2.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r49_BAG_L1_FULL ...\n",
      "\t0.61s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r143_BAG_L1_FULL ...\n",
      "\t2.52s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForest_r127_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t1.03s\t = Training   runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r94_BAG_L1_FULL ...\n",
      "\t1.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1_FULL ...\n",
      "\t28.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r128_BAG_L1_FULL ...\n",
      "\t9.44s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t0.6s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1_FULL ...\n",
      "\t2.92s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.59s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.57s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r30_BAG_L1_FULL ...\n",
      "\t1.14s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r49_BAG_L1_FULL ...\n",
      "\t0.81s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r5_BAG_L1_FULL ...\n",
      "\t0.56s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1_FULL ...\n",
      "\t11.73s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1_FULL ...\n",
      "\t2.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r143_BAG_L1_FULL ...\n",
      "\t0.83s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r178_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r31_BAG_L1_FULL ...\n",
      "\t1.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1_FULL ...\n",
      "\t8.81s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t5.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r60_BAG_L1_FULL ...\n",
      "\t0.9s\t = Training   runtime\n",
      "Fitting model: RandomForest_r15_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r135_BAG_L1_FULL ...\n",
      "\t1.7s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r22_BAG_L1_FULL ...\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t4.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r6_BAG_L1_FULL ...\n",
      "\t0.73s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t10.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r121_BAG_L1_FULL ...\n",
      "\t0.95s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t0.92s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r180_BAG_L1_FULL ...\n",
      "\t4.01s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1_FULL ...\n",
      "\t4.55s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r197_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1_FULL ...\n",
      "\t15.88s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t0.58s\t = Training   runtime\n",
      "Fitting model: RandomForest_r16_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t1.96s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r12_BAG_L1_FULL ...\n",
      "\t1.64s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1_FULL ...\n",
      "\t19.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t1.4s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1_FULL ...\n",
      "\t7.61s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t1.0s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r163_BAG_L1_FULL ...\n",
      "\t0.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r198_BAG_L1_FULL ...\n",
      "\t0.93s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1_FULL ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.77s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1_FULL ...\n",
      "\t4.12s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r95_BAG_L1_FULL ...\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r34_BAG_L1_FULL ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r42_BAG_L1_FULL ...\n",
      "\t6.08s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1_FULL ...\n",
      "\t20.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1_FULL ...\n",
      "\t12.44s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r143_BAG_L1': 1.0}\n",
      "\t0.09s\t = Training   runtime\n",
      "Updated best model to \"NeuralNetTorch_r143_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"NeuralNetTorch_r143_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 361.31s ... Best model: \"NeuralNetTorch_r143_BAG_L1_FULL\"\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (3044 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/bono/Library/CloudStorage/OneDrive-PolitecnicodiMilano/work/prin/llm-uncertainty/tablellama-high\")\n"
     ]
    }
   ],
   "source": [
    "X_train['label'] = y_train\n",
    "predictor = TabularPredictor(label='label', path='tablellama-high', log_to_file=True).fit(X_train, presets='high_quality')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8507b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['label'] = y_train\n",
    "# predictions = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7dc7f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.40      0.47       371\n",
      "        True       0.56      0.73      0.63       391\n",
      "\n",
      "    accuracy                           0.57       762\n",
      "   macro avg       0.57      0.56      0.55       762\n",
      "weighted avg       0.57      0.57      0.55       762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_proba = predictor.predict_proba(X_test)\n",
    "pred = pred_proba.values.argmax(axis=1).astype(bool)\n",
    "print(classification_report(y_test.values, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16567682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 204 ms, total: 1.55 s\n",
      "Wall time: 543 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "import xgboost\n",
    "\n",
    "#partition cv by prompt\n",
    "xgb_model = XGBRFClassifier(n_estimators=100, n_jobs=6)\n",
    "\n",
    "# pred = cross_val_predict(xgb_model, X, y, cv=GroupKFold(n_splits=10), groups=pids)\n",
    "# pred_proba = cross_val_predict(xgb_model, X, y, cv=LeaveOneGroupOut(), groups=pids, method='predict_proba')\n",
    "\n",
    "# pred_proba = cross_val_predict(xgb_model, X_res, y_res, cv=GroupKFold(n_splits=10), groups=pids_res, method='predict_proba')\n",
    "\n",
    "xgb_model.fit(X_train.drop(columns=['label']), y_train)\n",
    "pred_proba = xgb_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d14ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.50      0.56       371\n",
      "        True       0.61      0.74      0.67       391\n",
      "\n",
      "    accuracy                           0.62       762\n",
      "   macro avg       0.63      0.62      0.62       762\n",
      "weighted avg       0.63      0.62      0.62       762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = pred_proba.argmax(axis=1).astype(bool)\n",
    "print(classification_report(y_test.values, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91eb87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 1.57 s, total: 15.6 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "import xgboost\n",
    "\n",
    "#partition cv by prompt\n",
    "xgb_model = XGBRFClassifier(n_estimators=100, n_jobs=6)\n",
    "\n",
    "# pred = cross_val_predict(xgb_model, X, y, cv=GroupKFold(n_splits=10), groups=pids)\n",
    "# pred_proba = cross_val_predict(xgb_model, X, y, cv=LeaveOneGroupOut(), groups=pids, method='predict_proba')\n",
    "\n",
    "pred_proba = cross_val_predict(xgb_model, X_res, y_res, cv=GroupKFold(n_splits=10), groups=pids_res, method='predict_proba')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2646037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_proba.argmax(axis=1).astype(bool)\n",
    "print(classification_report(y_test.values, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a4937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
